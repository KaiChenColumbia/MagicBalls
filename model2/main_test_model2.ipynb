{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from deep_q_pong_networks\\network-599988\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for deep_q_pong_networks\\network-599988\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 653, in launch_instance\n    app.start()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-5cd912405364>\", line 209, in <module>\n    player = DeepQPongPlayerTest()\n  File \"<ipython-input-1-5cd912405364>\", line 75, in __init__\n    self._saver = tf.train.Saver()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1140, in __init__\n    self.build()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 688, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 663, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for deep_q_pong_networks\\network-599988\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for deep_q_pong_networks\\network-599988\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5cd912405364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m \u001b[0mplayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepQPongPlayerTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0mplayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5cd912405364>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_path, playback_mode, verbose_logging)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loaded checkpoints %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1560\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for deep_q_pong_networks\\network-599988\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 653, in launch_instance\n    app.start()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-5cd912405364>\", line 209, in <module>\n    player = DeepQPongPlayerTest()\n  File \"<ipython-input-1-5cd912405364>\", line 75, in __init__\n    self._saver = tf.train.Saver()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1140, in __init__\n    self.build()\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1172, in build\n    filename=self._filename)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 688, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 663, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\Suer Hu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for deep_q_pong_networks\\network-599988\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "# This is heavily based off https://github.com/asrivat1/DeepLearningVideoGames\n",
    "import os\n",
    "# os.environ['SDL_VIDEODRIVER']='dummy'\n",
    "import random\n",
    "from collections import deque\n",
    "from pong_player import PongPlayer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pygame.constants import K_DOWN, K_UP, K_RIGHT\n",
    "\n",
    "\n",
    "class DeepQPongPlayerTest(PongPlayer):\n",
    "    ACTIONS_COUNT = 3  # number of valid actions. In this case up, still and down\n",
    "    # FUTURE_REWARD_DISCOUNT = 0.99  # decay rate of past observations\n",
    "    OBSERVATION_STEPS = 20000.  # time steps to observe before training\n",
    "    EXPLORE_STEPS = 500000.  # frames over which to anneal epsilon\n",
    "    INITIAL_RANDOM_ACTION_PROB = 0.05  # starting chance of an action being random\n",
    "    FINAL_RANDOM_ACTION_PROB = 0.05  # final chance of an action being random\n",
    "    MEMORY_SIZE = 50000  # number of observations to remember\n",
    "    MINI_BATCH_SIZE = 100  # size of mini batches\n",
    "    STATE_FRAMES = 4  # number of frames to store in the state\n",
    "    RESIZED_SCREEN_X, RESIZED_SCREEN_Y = (80, 80)\n",
    "    OBS_LAST_STATE_INDEX, OBS_ACTION_INDEX, OBS_REWARD_INDEX, OBS_CURRENT_STATE_INDEX, OBS_TERMINAL_INDEX = range(5)\n",
    "    SAVE_EVERY_X_STEPS = 49999\n",
    "    LEARN_RATE = 1e-6\n",
    "    STORE_SCORES_LEN = 200.\n",
    "\n",
    "    def __init__(self, checkpoint_path=\"deep_q_pong_networks\", playback_mode=False, verbose_logging=False):\n",
    "        \"\"\"\n",
    "        Example of deep q network for pong\n",
    "\n",
    "        :param checkpoint_path: directory to store checkpoints in\n",
    "        :type checkpoint_path: str\n",
    "        :param playback_mode: if true games runs in real time mode and demos itself running\n",
    "        :type playback_mode: bool\n",
    "        :param verbose_logging: If true then extra log information is printed to std out\n",
    "        :type verbose_logging: bool\n",
    "        \"\"\"\n",
    "        self.reward_history = deque()\n",
    "        self.reward_memory = 0\n",
    "        \n",
    "        self._playback_mode = playback_mode\n",
    "        super(DeepQPongPlayerTest, self).__init__(force_game_fps=8)\n",
    "        self.verbose_logging = verbose_logging\n",
    "        self._checkpoint_path = checkpoint_path\n",
    "        if 1:\n",
    "            self._session = tf.Session()\n",
    "            self._input_layer, self._output_layer = DeepQPongPlayerTest._create_network()\n",
    "\n",
    "            self._action = tf.placeholder(\"float\", [None, self.ACTIONS_COUNT])\n",
    "            self._target = tf.placeholder(\"float\", [None])\n",
    "\n",
    "            readout_action = tf.reduce_sum(tf.multiply(self._output_layer, self._action), reduction_indices=1)\n",
    "\n",
    "            cost = tf.reduce_mean(tf.square(self._target - readout_action))\n",
    "            #self._train_operation = tf.train.AdamOptimizer(self.LEARN_RATE).minimize(cost)\n",
    "\n",
    "        self._observations = deque()\n",
    "        self._last_scores = deque()\n",
    "\n",
    "        # set the first action to do nothing\n",
    "        self._last_action = np.zeros(self.ACTIONS_COUNT)\n",
    "        self._last_action[1] = 1\n",
    "\n",
    "        self._last_state = None\n",
    "        self._probability_of_random_action = self.INITIAL_RANDOM_ACTION_PROB\n",
    "        self._time = 0\n",
    "\n",
    "        self._session.run(tf.global_variables_initializer())\n",
    "\n",
    "        if not os.path.exists(self._checkpoint_path):\n",
    "            os.mkdir(self._checkpoint_path)\n",
    "        \n",
    "        self._saver = tf.train.Saver()\n",
    "        checkpoint = tf.train.get_checkpoint_state(self._checkpoint_path)\n",
    "\n",
    "        if 1:\n",
    "            self._saver.restore(self._session, checkpoint.model_checkpoint_path)\n",
    "            print(\"Loaded checkpoints %s\" % checkpoint.model_checkpoint_path)\n",
    "\n",
    "    def get_keys_pressed(self, screen_array, reward, terminal):\n",
    "        # scale down screen image\n",
    "        screen_resized_grayscaled = cv2.cvtColor(cv2.resize(screen_array,\n",
    "                                                            (self.RESIZED_SCREEN_X, self.RESIZED_SCREEN_Y)),\n",
    "                                                 cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # set the pixels to all be 0. or 1.\n",
    "        _, screen_resized_binary = cv2.threshold(screen_resized_grayscaled, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        #if reward != 0.0:\n",
    "            # self._last_scores.append(reward)\n",
    "            #if len(self._last_scores) > self.STORE_SCORES_LEN:\n",
    "            #    self._last_scores.popleft()\n",
    "\n",
    "        # first frame must be handled differently\n",
    "        if self._last_state is None:\n",
    "            # the _last_state will contain the image data from the last self.STATE_FRAMES frames\n",
    "            self._last_state = np.stack(tuple(screen_resized_binary for _ in range(self.STATE_FRAMES)), axis=2)\n",
    "\n",
    "            return DeepQPongPlayerTest._key_presses_from_action(self._last_action)\n",
    "\n",
    "        screen_resized_binary = np.reshape(screen_resized_binary,\n",
    "                                               (self.RESIZED_SCREEN_X, self.RESIZED_SCREEN_Y, 1)) ## 图像处理结束\n",
    "        \n",
    "        current_state = np.append(self._last_state[:, :, 1:], screen_resized_binary, axis=2)\n",
    "\n",
    "\n",
    "        # store the transition in previous_observations\n",
    "        self._observations.append((self._last_state, self._last_action, reward, current_state, terminal))\n",
    "\n",
    "\n",
    "\n",
    "            # only train if done observing\n",
    "\n",
    "        self._time += 1\n",
    "            \n",
    "        # update the old values\n",
    "        self._last_state = current_state\n",
    "        \n",
    "        self._last_action = self._choose_next_action()\n",
    "\n",
    "          \n",
    "        self.reward_memory += reward\n",
    "        if (self._time >= self.EXPLORE_STEPS-1):\n",
    "            return [K_RIGHT]    \n",
    "        return DeepQPongPlayerTest._key_presses_from_action(self._last_action)\n",
    "\n",
    "    def _choose_next_action(self):\n",
    "        new_action = np.zeros([self.ACTIONS_COUNT])\n",
    "\n",
    "        if (random.random() <= self._probability_of_random_action):\n",
    "            # choose an action randomly\n",
    "            action_index = random.randrange(self.ACTIONS_COUNT)\n",
    "        else:\n",
    "            # choose an action given our last state\n",
    "            readout_t = self._session.run(self._output_layer, feed_dict={self._input_layer: [self._last_state]})[0]\n",
    "            if self.verbose_logging:\n",
    "                print(\"Action Q-Values are %s\" % readout_t)\n",
    "            action_index = np.argmax(readout_t)\n",
    "\n",
    "        new_action[action_index] = 1\n",
    "        return new_action # \n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_network():\n",
    "        # network weights\n",
    "        if 1:\n",
    "            convolution_weights_1 = tf.Variable(tf.truncated_normal([8, 8, DeepQPongPlayerTest.STATE_FRAMES, 32], stddev=0.01))\n",
    "            convolution_bias_1 = tf.Variable(tf.constant(0.01, shape=[32]))\n",
    "\n",
    "            convolution_weights_2 = tf.Variable(tf.truncated_normal([4, 4, 32, 64], stddev=0.01))\n",
    "            convolution_bias_2 = tf.Variable(tf.constant(0.01, shape=[64]))\n",
    "\n",
    "            convolution_weights_3 = tf.Variable(tf.truncated_normal([3, 3, 64, 64], stddev=0.01))\n",
    "            convolution_bias_3 = tf.Variable(tf.constant(0.01, shape=[64]))\n",
    "\n",
    "            feed_forward_weights_1 = tf.Variable(tf.truncated_normal([256, 256], stddev=0.01))\n",
    "            feed_forward_bias_1 = tf.Variable(tf.constant(0.01, shape=[256]))\n",
    "\n",
    "            feed_forward_weights_2 = tf.Variable(tf.truncated_normal([256, DeepQPongPlayerTest.ACTIONS_COUNT], stddev=0.01))\n",
    "            feed_forward_bias_2 = tf.Variable(tf.constant(0.01, shape=[DeepQPongPlayerTest.ACTIONS_COUNT]))\n",
    "\n",
    "            input_layer = tf.placeholder(\"float\", [None, DeepQPongPlayerTest.RESIZED_SCREEN_X, DeepQPongPlayerTest.RESIZED_SCREEN_Y,\n",
    "                                               DeepQPongPlayerTest.STATE_FRAMES])\n",
    "\n",
    "            hidden_convolutional_layer_1 = tf.nn.relu(\n",
    "                tf.nn.conv2d(input_layer, convolution_weights_1, strides=[1, 4, 4, 1], padding=\"SAME\") + convolution_bias_1)\n",
    "\n",
    "            hidden_max_pooling_layer_1 = tf.nn.max_pool(hidden_convolutional_layer_1, ksize=[1, 2, 2, 1],\n",
    "                                                    strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "            hidden_convolutional_layer_2 = tf.nn.relu(\n",
    "                tf.nn.conv2d(hidden_max_pooling_layer_1, convolution_weights_2, strides=[1, 2, 2, 1],\n",
    "                         padding=\"SAME\") + convolution_bias_2)\n",
    "\n",
    "            hidden_max_pooling_layer_2 = tf.nn.max_pool(hidden_convolutional_layer_2, ksize=[1, 2, 2, 1],\n",
    "                                                    strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "            hidden_convolutional_layer_3 = tf.nn.relu(\n",
    "                tf.nn.conv2d(hidden_max_pooling_layer_2, convolution_weights_3,\n",
    "                         strides=[1, 1, 1, 1], padding=\"SAME\") + convolution_bias_3)\n",
    "\n",
    "            hidden_max_pooling_layer_3 = tf.nn.max_pool(hidden_convolutional_layer_3, ksize=[1, 2, 2, 1],\n",
    "                                                    strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "            hidden_convolutional_layer_3_flat = tf.reshape(hidden_max_pooling_layer_3, [-1, 256])\n",
    "\n",
    "            final_hidden_activations = tf.nn.relu(\n",
    "                tf.matmul(hidden_convolutional_layer_3_flat, feed_forward_weights_1) + feed_forward_bias_1)\n",
    "\n",
    "            output_layer = tf.matmul(final_hidden_activations, feed_forward_weights_2) + feed_forward_bias_2\n",
    "\n",
    "        return input_layer, output_layer \n",
    "\n",
    "    @staticmethod\n",
    "    def _key_presses_from_action(action_set):\n",
    "        if action_set[0] == 1:\n",
    "            return [K_DOWN]\n",
    "        elif action_set[1] == 1:\n",
    "            return []\n",
    "        elif action_set[2] == 1:\n",
    "            return [K_UP]\n",
    "        raise Exception(\"Unexpected action\") \n",
    "\n",
    "\n",
    "\n",
    "player = DeepQPongPlayerTest()\n",
    "player.start()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
